# Casos-de-prueba-llm-owasp

Objetivo del repositorio

Resumen del benchmark

Metodología ✅

Cómo seleccionaste los ataques

Por qué esos 7 del OWASP Top 10

Criterios de priorización

Entorno de pruebas ✅

Qué modelo LLM estás usando

Cómo se simulan los ataques

Herramientas utilizadas (mención general)

Estructura del repositorio

Cómo contribuir o ejecutar los casos

Enlaces a versiones o carpetas

--------------
Para acceder a la primera versión, [haga clic aquí](./pruebas-v1/README.md).

## Contenido
Este repositorio contiene un plan de pruebas compuesto por 7 casos de ataque, diseñados para evaluar la seguridad de aplicaciones que integran modelos de lenguaje grandes (LLMs). Cada caso aborda un tipo específico de amenaza descrita en el OWASP Top 10 para sistemas con LLMs.

A continuación se presentan los casos actualmente implementados:

+ LLM01: 2025 - **Prompt Injection**
+ LLM02: 2025 - **Sensitive Information Disclosure**
+ LLM03: 2025 - **Supply Chain**
+ LLM04: 2025 - **Data and Model Poisoning**
+ LLM05: 2025 - **Improper Output Handling**
+ LLM09: 2025 - **Misinformation**
+ LLM10: 2025 - **Unbounded Consumption**
